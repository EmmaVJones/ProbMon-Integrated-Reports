---
title: "How to Write Probabilistic Monitoring Integrated Report Chapter"
output:
  html_document:
    df_print: paged
---

This document walks you through the steps of pulling data, running analyses, and writing the Integrated Report chapter for the Probabilistic Monitoring Program due to EPA every two years. This document overviews the 2018 IR ProbMon chapter and the Change Analysis chapter due every ~6 years.

### Data Organization
Starting with the EnviroSmash dataset (organized for the 2018 VA attribution/BCG project), this spreadsheet has combined all necessary ProbMon, Targeted stress, NRSA/MAHA/MAIA, and other state/county data. This spreadsheet needs to be filtered to only include DEQ Probmon data.

```{r startup, echo=FALSE, warning=FALSE}
# R version 3.4.4 "Someone to Lean On"
suppressPackageStartupMessages(library(tidyverse))#1.2.1
suppressPackageStartupMessages(library(sf))#0.6-1
suppressPackageStartupMessages(library(spsurvey))#3.3

```


```{r filterProbMonONLY}
# Bring in Envirosmash data from BCG organization, limit to VDEQ probmon sites only, filter to just 2018 IR window (2011-2016)
allProb <- readxl::read_excel('originalData/EnviroDataSmashV10EVJJRH.xlsx',sheet='stressorData_EVJ') %>%
  filter(DataSource=="State ProbMon") %>% # Get rid of other datasources
  mutate(IR2018= ifelse(Year >= 2011 & Year <= 2016, 2018,NA)) %>% # Identify sites within the 2018 IR window
  select("DataSource","StationID","Year","StationID_Trend","LongitudeDD","LatitudeDD", 
         "stratum","designweight","weightcategory","station","state","status","comment",
         "set","Basin","SubBasin","BayShed","BayPanel","EcoRegion","BioRegion","Panel",
         "BioPanel","Order","BasinSize","StreamSizeCat","StreamSizeCatPhase",
         "AREA_SQ_MILES","IR2008","IR2010","IR2012","IR2014","IR2016","IR2018",everything()) # rearrange column order
# Just IR window data
probIR <- filter(allProb, Year >= 2011 & Year <= 2016) # Get rid of data outside window

```

Do some QA on data. First look to see what data is missing from new years in IR window (2015, 2016).
```{r initialQA}
DT::datatable(select(probIR,StationID,Year, stratum, designweight, weightcategory, station,status,comment, set, Order, BasinSize, StreamSizeCat, AREA_SQ_MILES,EcoRegion, Basin, SubBasin, designweighttrend, designweightoriginal, filwgt_trend, filwgt_orgil, VSCIVCPMI) %>%
       arrange(desc(Year)))
```

So none of the design weight stuff is filled in. It appears that weightcategory = Order but first double check that this is always true.
```{r weightCatEqualsStreamOrder}
DT::datatable(probIR[probIR$Order!=probIR$weightcategory,]) # 6AFOX001.69 is a 1st order but in 2 weight category, need to fix that
```
6AFOX001.69 is incorrectly labeled in either Order or weight category.
Using GIS we see it is definitely 2nd order at 1:100000 scale (vafrm_99 layer).
![6AFOX001.69](originalData/6AFOX001.69.PNG)

So we need to manually change the weight category to match the stream order in both probIR dataframe and allProb. The most efficient way to do that is to fix the allProb dataframe and then filter out only IR window data for probIR again later.
**Note 6AFOX001.69 has had a mix of 1st and 2nd order designations throughout the years with 2004 and 2015 only having the correct 2nd order designation. Weight category has always been 2, which is most important for estimates so that's good news.**
```{r fixWeightCat}
allProb[allProb$StationID=='6AFOX001.69',c("StationID","StationID_Trend","weightcategory","Order")]
allProb[allProb$StationID=='6AFOX001.69',]$Order <- c("2","2","2","2")
```
Then filter out probIR again to update that dataframe with new data.
```{r}
probIR <- filter(allProb, Year >= 2011 & Year <= 2016) # Get rid of data outside window
#View(probIR[probIR$Order!=probIR$weightcategory,]) # run this to double check everything is cool now
```


#### Design weights
Time to assign design weights for all new (2015,2016) data according to the existing weight breakdown (listed below). Design weight is critical to basically everything from here out. Again, we will complete these changes on the full dataset (allProb) and filter our just IR years to update that dataset after manipulations are complete.

**Note: I need to overwrite designweights from previous years back to original weight (data from 2001-2014) such that I can adjust for trend stations. If I dont overwrite previous years then they willnot reflect teh correct weight based on designweight/nYearsSampled**


Do these weights stay the same as new data is added?
```{r assignDesignWeights}
allProb <- mutate(allProb,designweight = Order) %>% # need to overwrite all design weights
  mutate(designweight = dplyr::recode(designweight,`1`="3790.5165999999999",`2`="947.62919999999997", 
                                      `3`="541.50239999999997",`4`="315.87639999999999", 
                                      `5`="140.3895", `6`="140.3895"))

DT::datatable(select(allProb,StationID_Trend,Year,Order,designweight,
                     designweighttrend, designweightoriginal, filwgt_trend, filwgt_orgil))
```

Now we readjust the weights if the station has been sampled more than once (trend site). We divide the n times sampled by weight to get out designweight_trend number. This time we need to adjust all the design weights (even before 2015) because the weight needs to reflect all sample dates.
```{r adjustDesignWeightForTrend}
allProb <- allProb %>% 
  group_by(StationID) %>%
  mutate(nYearsSampled = n()) %>%
  mutate(designweight = as.numeric(designweight) / nYearsSampled,
         designweighttrend = designweight,
         designweightoriginal = as.numeric(designweight))

DT::datatable(select(allProb,StationID, StationID_Trend,Year,Order,designweight,designweighttrend,nYearsSampled))

#View(probIR[probIR$designweight!=probIR$designweighttrend,])
```

#### spsurvey and final weight calculations
Use the spsurvey package and use the initial weights (not divided out by years sampled) to calculate the final weights. Then we need to divide the final weights by the n years sampled before moving on to CDF calculations. 

** Not sure if this is entirely correct bc no 7th order in our DB**

```{r}
# sample frame basic inputs
# List stream kilometer by km
sframe <- c('1st'=51210, '2nd'=13680, '3rd'=7781.08, '4th'=4448.257, 
            '5th'=1731.302, '6th'=163.901, '7th'=14.7099 )


finalWeights <- select(allProb,StationID, Year, LongitudeDD, LatitudeDD, designweightoriginal,
                       Order,nYearsSampled,filwgt_trend,filwgt_orgil)

finalWeights$Order <- as.factor(finalWeights$Order)
levels(finalWeights$Order) <- c('1st','2nd','3rd','4th','5th','6th','7th')
#table(finalWeights$Order,dsgnstatus$MDCaty)
wgt <- sframe/table(finalWeights$Order)

finalWeights$filwgt_orgil2 <- adjwgt(rep(TRUE,nrow(finalWeights)), 
                                finalWeights$designweightoriginal,
                                finalWeights$Order, sframe)
finalWeights <- mutate(finalWeights, filwgt_trend2=filwgt_orgil2/nYearsSampled)

```

Change decimal degree coordinates to marinus for equal area projection (needed for spsurvey::cat.analysis())
```{r}
marinus <- spsurvey::marinus(finalWeights$LatitudeDD,finalWeights$LongitudeDD)
finalWeights2 <- cbind(finalWeights,marinus)

```



**Need to adjust filwgt_trend and filwgt_orgil as well but dividing the final weights calculated by spsurvey by n years sampled. Need correct stream order designation though to match input data to biology.R with stream order going up to 7. There is a good probability that the numbers i assigned earlier are not correct given that there is new data and I am stopping here. **

**Where do I get something like this from the start of biology.R??**
```{r}
DT::datatable(read.delim('analysis/biology.tab',comment.char = ""))
```





### Maps

Now time to make maps of sites sampled across the state for the introduction part of chapter. First you need to make shapefiles from both allProb and probIR data, then pull watersheds from IR window from Landcover GIS database. I created the GIS project "MapDataOrganization.mxd" to overview the process.

```{r, GISwrangling}
# Make sf object of all sites ever sampled for Probmon program
allProb_sf <- select(allProb, StationID, LatitudeDD, LongitudeDD, Year, Order, BasinSize,
                     AREA_SQ_MILES, IR2008, IR2010, IR2012, IR2014, IR2016, IR2018) %>%
  st_as_sf( coords = c("LongitudeDD", "LatitudeDD"), 
            crs = "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
# Limit to just sites sampled in 2018IR window
probIR_sf <- select(probIR, StationID, LatitudeDD, LongitudeDD, Year, Order, BasinSize,
                     AREA_SQ_MILES, IR2008, IR2010, IR2012, IR2014, IR2016, IR2018) %>%
  st_as_sf( coords = c("LongitudeDD", "LatitudeDD"), 
            crs = "+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")

# Bring in watershed data
allWshd <- st_as_sf(rgdal::readOGR('C:/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb','AllWatersheds_through2016')) # bring it in as sf object
# Get rid of any stray spaces after StationID in attribute table
allWshd$StationID <- sub("\r\n" ,"",allWshd$StationID) 

# Limit to just watersheds sampled in 2018IR window
probIRwshd <- filter(allWshd,StationID %in% probIR$StationID)

# I still need these watersheds in teh GIS database and need to run landcover
#probIR[!(probIR$StationID %in% allWshd$StationID),]$StationID

```

Now write a shapefile for the 2018 IR wadeable sites for our records and to make the plots easier.

```{r IR2018wadeableSites}

st_write(probIR_sf, "processedData/IRstations2018.shp", delete_layer = TRUE) # delete_layer=T overwrites previous layer by that name

```


Cool, now get boatable sites and watersheds organized (just for map visualization, not for reporting purposes). In the latest copy of Fish EDAS, run the StationQuery and export to originalData folder.

```{r}
boatableSites <- readxl::read_excel('originalData/FishEDAS_StationQuery.xlsx',sheet = 'StationQuery') %>%
  filter(CollMeth %in% c("Boat","BP/Boat","boat/bp"))
boatableSitesIR <- filter(boatableSites, CollDate > "2011-01-01" & CollDate < "2016-12-31")

# now find watersheds that match boatable StationID's
boatableWshd <- filter(allWshd,StationID %in% boatableSites$StationID)

# sites I still need delineated, including the 2 wadeable sites
sort(c(boatableSites[!(boatableSites$StationID %in% allWshd$StationID),]$StationID,
  probIR[!(probIR$StationID %in% allWshd$StationID),]$StationID))

```


And bring in VAbasins layer for backdrop of maps as well as previous IR years spatial layers.
```{r basinLayer}
VAbasins <- rgdal::readOGR('originalData','basinsstatewide')
IRstations2018 <- rgdal::readOGR("processedData","IRstations2018")

# Bring in shapefile already made of previous IR sites by window
IRstations <- rgdal::readOGR('originalData','MasterIRStationList')
# a little data management action
IRstations2008 <- subset(IRstations, IRstations@data$IR2008 == '2008')
IRstations2010 <- subset(IRstations, IRstations@data$IR2010 == '2010')
IRstations2012 <- subset(IRstations, IRstations@data$IR2012 == '2012')
IRstations2014 <- subset(IRstations, IRstations@data$IR2014 == '2014')
IRstations2016 <- subset(IRstations, IRstations@data$IR2016 == '2016')


```



Plots that I will need to update for 2018
##### Figure 2.4-2. Virginia probabilistic monitoring locations from 2011-2016 (n=262).
```{r eval=F,fig.width=5.75, fig.height=2.75}  
par(mar=c(0,0,0,0),oma=c(0,0,0,0))
plot(VAbasins,border='wheat3',col='wheat1',ylim=c(37.4,38.5))
plot(IRstations2018,col='grey21',pch=19,cex=0.5,add=T)
legend('left',legend=c('Major Basins','Probabilistic Sites (Wadeable)')
       ,title='Legend',bty='n',inset=0.05,pch=c(15,15,19),cex=0.8
       ,col=c('wheat1','grey21'))
```

##### Figure 2.4-3. Virginia probabilistic monitoring wadeable locations from 2001-2016 (n=736).
```{r eval=F,fig.width=5.75, fig.height=2.5}  
par(mar=c(0,0,0,0),oma=c(0,0,0,0))
plot(VAbasins,border='wheat3',col='wheat1',ylim=c(37.4,38.5))
plot(IRstations2008,col='red',pch=19,cex=0.5,add=T)
plot(IRstations2010,col='blue',pch=19,cex=0.5,add=T)
plot(IRstations2012,col='green',pch=19,cex=0.5,add=T)
plot(IRstations2014,col='purple',pch=19,cex=0.5,add=T)
plot(IRstations2016,col='orange',pch=19,cex=0.5,add=T)
plot(IRstations2018,col='black',pch=19,cex=0.5,add=T)
legend('topleft',legend=c('Major Basins','2008 IR wadeable sites',
                          '2010 IR wadeable sites','2012 IR wadeable sites',
                          '2014 IR wadeable sites','2016 IR wadeable sites',
                          '2018 IR wadeable sites'),
       title='Legend',bty='n',inset=0.05,pch=c(15,19,19,19,19,19,19),cex=0.8,
       col=c('wheat1','red','blue','green','purple','orange','gray'))
```

##### Figure 2.4-4. Virginia probabilistic monitoring wadeable and boatable watersheds and sample sites  from 2001-2016 (n=715).
```{r eval=F,fig.width=5.75, fig.height=3}  
par(mar=c(0,0,0,0),oma=c(0,0,0,0))
plot(VAbasins,border='wheat3',col='wheat1',ylim=c(37.4,38.5))
plot(boatableWshd,border='lightskyblue4',col='grey',add=T)
plot(IRwshds,border='lightskyblue4',col='lightskyblue',add=T)
plot(IRstations,col='grey21',pch=19,cex=0.5,add=T)
plot(boatableYES2014,col='red',pch=19,cex=0.5,add=T)
legend('topleft',legend=c('Major Basins','Monitored Watersheds (Boatable)','Monitored Watersheds (Wadeable)'
                       ,'Boatable Sites (2008 - 2014)','Wadeable Sites (2001 - 2014)')
       ,title='Legend',bty='n',inset=0.05,pch=c(15,15,15,19,19),cex=0.8
       ,col=c('wheat1','grey','lightskyblue','red','grey21'))
```


